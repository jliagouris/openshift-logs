{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Openshift Log Analysis\n",
    "\n",
    "This is a notebook to analyze the logs of an OpenShift cluster. The notebook queries the logs of the cluster and checks simple things like the number of logs, the number of services, the number of json messages, json schema frequency, the number of replicas, common patterns in json/non-json messages and etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "query = \"{cluster_log_level=\\\"app-logs\\\", openshift_cluster=\\\"moc/smaug\\\"} |= \\\"error\\\"\"\n",
    "start = \"1652736197\"\n",
    "end = \"1652746829\"\n",
    "limit = \"5000\"\n",
    "\n",
    "x_scope_org_id = \"cluster-app-logs\"\n",
    "token = \"\"\n",
    "\n",
    "data = fetch_loki_logs(token, x_scope_org_id, query, start, end, limit)\n",
    "print(f\"{len(data)} entries found\")\n",
    "\n",
    "for stream in data:\n",
    "    namespace = stream['stream']['k8s_namespace_name'] if 'k8s_namespace_name' in stream['stream'].keys() else 'unknown'\n",
    "    log_level = stream['stream']['cluster_log_level']\n",
    "    cluster = stream['stream']['openshift_cluster']\n",
    "    lnx = len(stream['values'])\n",
    "    print(f\"Log level: {log_level}\\tCluster: {cluster}\\tEntries: {lnx}\\tNamespace: {namespace}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema_frequency = {}\n",
    "non_json_info = {}\n",
    "json_logs = {}\n",
    "levels = []\n",
    "\n",
    "json_count = 0\n",
    "non_json_count = 0\n",
    "\n",
    "for stream in data:\n",
    "    namespace = stream['stream']['k8s_namespace_name'] if 'k8s_namespace_name' in stream['stream'].keys() else 'unknown'\n",
    "    log_level = stream['stream']['cluster_log_level']\n",
    "    cluster = stream['stream']['openshift_cluster']\n",
    "    \n",
    "    for val_list in stream['values']:\n",
    "        value = json.loads(val_list[1])\n",
    "        message = value['message']\n",
    "\n",
    "        try:\n",
    "            json_message = json.loads(message)\n",
    "            keys = json_message.keys()\n",
    "            for key in keys:\n",
    "                if key not in json_schema_frequency.keys():\n",
    "                    json_schema_frequency[key] = {}\n",
    "                    json_schema_frequency[key]['type'] = type(json.loads(message)[key]).__name__\n",
    "                    json_schema_frequency[key]['count'] = 1\n",
    "                    json_schema_frequency[key]['example'] = json_message[key]\n",
    "                else:\n",
    "                    json_schema_frequency[key]['count'] += 1\n",
    "            json_count += 1\n",
    "            \n",
    "            if namespace not in json_logs.keys():\n",
    "                json_logs[namespace] = [json_message]\n",
    "            else:\n",
    "                json_logs[namespace].append(json_message)\n",
    "\n",
    "            if 'level' in json_message.keys():\n",
    "                levels.append(json_message['level'])\n",
    "        except:\n",
    "            if namespace not in non_json_info.keys():\n",
    "                non_json_info[namespace] = [message]\n",
    "            else:\n",
    "                non_json_info[namespace].append(message)\n",
    "            non_json_count += 1\n",
    "\n",
    "print(f\"{non_json_count} non-json messages, {json_count} json keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in json_schema_frequency.keys():\n",
    "    print(f\"{key},{json_schema_frequency[key]['type']},{json_schema_frequency[key]['count']},{json_schema_frequency[key]['example']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in json_logs:\n",
    "    print(f\"{key}\")\n",
    "    for log in json_logs[key][:10]:\n",
    "        print(f\"{log}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "mx = list(sorted([len(non_json_info[key]) for key in non_json_info]))[-10:]\n",
    "\n",
    "\n",
    "for key in non_json_info:\n",
    "    if len(non_json_info[key]) in mx:\n",
    "        print(key)\n",
    "        random.shuffle(non_json_info[key])\n",
    "        print('\\n'.join(non_json_info[key][:10]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}